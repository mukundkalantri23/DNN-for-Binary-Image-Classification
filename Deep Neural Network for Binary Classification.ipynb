{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network\n",
    "We will build a flexible neural network with L layers that can have different hidden layer units in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "1. Import packages and load data.\n",
    "2. Standardize data to have feature values between 0 and 1.\n",
    "3. Define all L layers with their number of hidden units and activation function for each layer.\n",
    "4. Initialize parameters.\n",
    "5. Loop for num_iterations:\n",
    "   - Forward propagation\n",
    "   - Compute cost function\n",
    "   - Backward propagation\n",
    "   - Update parameters (using parameters, and grads from backprop) \n",
    "6. Use trained parameters to predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "#display the output of plotting commands on the frontend of the notebook.\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "# interpolation='nearest' simply displays an image without trying to interpolate between pixels if \n",
    "# the display resolution is not the same as the image resolution (which is most often the case). \n",
    "# It will result an image in which pixels are displayed as a square of multiple pixels.\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray' # set the default color map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_dataset = h5py.File('train_catvnoncat.h5','r')\n",
    "    #print(list(train_dataset.keys())) #shows a list of column headings in a h5py file.\n",
    "    x_train_orig = np.array(train_dataset['train_set_x'][:])\n",
    "    y_train = np.array(train_dataset['train_set_y'][:])\n",
    "\n",
    "    test_dataset = h5py.File('test_catvnoncat.h5','r')\n",
    "    x_test_orig = np.array(test_dataset['test_set_x'][:])\n",
    "    y_test = np.array(test_dataset['test_set_y'][:])\n",
    "\n",
    "    classes = np.array(train_dataset['list_classes'][:])\n",
    "\n",
    "    # now we have to reshape our output values to make it into a vector\n",
    "    y_train = y_train.reshape(1,y_train.shape[0])\n",
    "    y_test = y_test.reshape(1,y_test.shape[0])\n",
    "    # print(x_train_orig.shape, y_train.shape, x_test_orig.shape, y_test.shape) will output\n",
    "    #      (209, 64, 64, 3)     (1, 209)       (50, 64, 64, 3)    (1, 50)\n",
    "    return (x_train_orig, y_train, x_test_orig, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(x_train_orig, x_test_orig):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x_train_orig -- input training values of dimensions (209, 64, 64, 3)\n",
    "    x_test_orig -- input test values of dimensions (50, 64, 64, 3)\n",
    "    \n",
    "    Returns:\n",
    "    x_train -- transformed input training values of dimensions (12288, 209)\n",
    "    x_test -- transformed input test values of dimensions (12288, 50)\n",
    "    \"\"\"\n",
    "    \n",
    "    # now we have to reshape our data to make our input vector \n",
    "    x_train = x_train_orig.reshape(x_train_orig.shape[0], -1).T\n",
    "    x_test = x_test_orig.reshape(x_test_orig.shape[0], -1).T\n",
    "    # the \"-1\" makes reshape flatten the remaining dimensions\n",
    "\n",
    "    # Standardize data to have feature values between 0 and 1.\n",
    "    x_train = x_train/255\n",
    "    x_test = x_test/255\n",
    "    # generally to standardize data between 0 and 1, we divide all values by the maximum possible value,\n",
    "    # which here is the maximum value of a pixel: 255\n",
    "    return (x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(1) # It is used to keep all the random function calls consistent.\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) #total number of layers of the neural network\n",
    "    for l in range(1,L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])/ np.sqrt(layer_dims[l-1])#*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    a = 1/(1+np.exp(-z))\n",
    "    return a\n",
    "\n",
    "def relu(z):\n",
    "    a = np.maximum(0,z)\n",
    "    return a\n",
    "\n",
    "def dZ_sigmoid(dA, z):\n",
    "    s = sigmoid(z)\n",
    "    dZ = dA * s * (1-s)\n",
    "    return dZ\n",
    "\n",
    "def dZ_relu(dA,z):\n",
    "    dZ = np.array(dA, copy = True) # copy input values into an array to avoid overwriting on the same values\n",
    "    dZ[z<=0] = 0 # slope for values <=0 would be 0 else 1\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, parameters, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input values of dimension(12288, 209)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    Y_pred -- predicted output values of dimension(1,209)\n",
    "    Z_cache -- the input of the activation function of all layers in a dictionary\n",
    "    A_cache -- the output of activation function of all layers in a dictionary\n",
    "    \"\"\"\n",
    "    L = len(activation)\n",
    "    A_prev = X\n",
    "    Z_cache = {}\n",
    "    A_cache = {'A0':X}\n",
    "    for l in range(L):\n",
    "        W = parameters['W' + str(l+1)]\n",
    "        b = parameters['b' + str(l+1)]\n",
    "        Z = np.dot(W,A_prev)+b\n",
    "        if activation[l] == 'sigmoid':\n",
    "            A = sigmoid(Z)\n",
    "        elif activation[l] == 'relu':\n",
    "            A = relu(Z)\n",
    "        A_prev = A\n",
    "        Z_cache['Z' + str(l+1)] = Z\n",
    "        A_cache['A' + str(l+1)] = A\n",
    "    Y_pred = A\n",
    "    return (Y_pred, Z_cache, A_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y_pred, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Y_pred -- predicted output values of dimension(1,209)\n",
    "    Y -- original output values of dimension(1,209)\n",
    "    \n",
    "    Returns:\n",
    "    cost -- cross entropy cost\n",
    "    dCost -- derivative of the cross entropy cost function of dimension (1,209)\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m) * (np.dot(Y,np.log(Y_pred).T) + np.dot(1-Y,np.log(1-Y_pred).T))\n",
    "    dCost = - (np.divide(Y,Y_pred) - np.divide(1-Y,1-Y_pred))\n",
    "    return cost, dCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(dCost, Z_cache, A_cache, activation, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dCost -- derivative of the cross entropy cost function of dimension (1,209)\n",
    "    Z_cache -- the input of the activation function of all layers in a dictionary\n",
    "    A_cache -- the output of activation function of all layers in a dictionary\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- dictionary containing gradients (dW and db) of all layers\n",
    "    \"\"\"\n",
    "    dA = dCost\n",
    "    m = dA.shape[1]\n",
    "    grads = {}\n",
    "    L = len(activation)\n",
    "    for l in reversed(range(L)):\n",
    "        # 3 2 1 0\n",
    "        #print(list(A_cache.keys())[l])\n",
    "        A_prev = A_cache['A' + str(l)]\n",
    "        Z = Z_cache['Z' + str(l+1)]\n",
    "        W = parameters['W' + str(l+1)]\n",
    "        if activation[l] == 'sigmoid':\n",
    "            dZ = dZ_sigmoid(dA, Z)\n",
    "        elif activation[l] == 'relu':\n",
    "            dZ = dZ_relu(dA, Z)\n",
    "        dW = (1/m) * np.dot(dZ,A_prev.T)\n",
    "        db = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA = np.dot(W.T,dZ)\n",
    "        grads['dW' + str(l+1)] = dW\n",
    "        grads['db' + str(l+1)] = db\n",
    "    return grads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(grads, parameters, learning_rate):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    grads -- dictionary containing gradients (dW and db) of all layers\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    learning_rate -- learning rate to set the speed of model training\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    L = len(grads)//2\n",
    "    for l in range(L):\n",
    "        parameters['W' + str(l+1)] -= learning_rate * grads['dW' + str(l+1)]\n",
    "        parameters['b' + str(l+1)] -= learning_rate * grads['db' + str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, parameters, activation, num_iterations = 3000, print_cost=False):\n",
    "    m = y_train.shape[1]\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        Y_pred, Z_cache, A_cache = forward_pass(x_train, parameters, activation)\n",
    "        cost, dCost = compute_cost(Y_pred, y_train)\n",
    "        grads = backward_pass(dCost, Z_cache, A_cache, activation, parameters)\n",
    "        parameters = update_params(grads, parameters, learning_rate)\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    plt.plot(np.squeeze(costs)) # plot the cost\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()     \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, parameters, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input data set\n",
    "    Y -- original output of the data set \n",
    "    parameters -- parameters of the trained model\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    Y_pred, Z_cache, A_cache = forward_pass(X, parameters, activation)\n",
    "    # convert output to 0/1 predictions\n",
    "    p[Y_pred>0.5] = 1 # if true then 1 else 0\n",
    "    accuracy = np.sum(p == Y)*(100/m)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.7717493284237686\n",
      "Cost after iteration 100: 0.6720534400822914\n",
      "Cost after iteration 200: 0.6482632048575212\n",
      "Cost after iteration 300: 0.6115068816101354\n",
      "Cost after iteration 400: 0.5670473268366111\n",
      "Cost after iteration 500: 0.54013766345478\n",
      "Cost after iteration 600: 0.5279299569455267\n",
      "Cost after iteration 700: 0.4654773771766851\n",
      "Cost after iteration 800: 0.3691258524959279\n",
      "Cost after iteration 900: 0.39174697434805344\n",
      "Cost after iteration 1000: 0.3151869888600617\n",
      "Cost after iteration 1100: 0.2726998441789385\n",
      "Cost after iteration 1200: 0.23741853400268137\n",
      "Cost after iteration 1300: 0.19960120532208647\n",
      "Cost after iteration 1400: 0.18926300388463305\n",
      "Cost after iteration 1500: 0.1611885466582775\n",
      "Cost after iteration 1600: 0.14821389662363316\n",
      "Cost after iteration 1700: 0.13777487812972944\n",
      "Cost after iteration 1800: 0.1297401754919012\n",
      "Cost after iteration 1900: 0.12122535068005211\n",
      "Cost after iteration 2000: 0.1138206066863371\n",
      "Cost after iteration 2100: 0.10783928526254133\n",
      "Cost after iteration 2200: 0.10285466069352679\n",
      "Cost after iteration 2300: 0.10089745445261787\n",
      "Cost after iteration 2400: 0.09287821526472397\n",
      "Cost after iteration 2500: 0.0884125117761504\n",
      "Cost after iteration 2600: 0.08595130416146429\n",
      "Cost after iteration 2700: 0.08168126914926337\n",
      "Cost after iteration 2800: 0.07824661275815534\n",
      "Cost after iteration 2900: 0.07544408693855482\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "num_iterations = 3000\n",
    "learning_rate = 0.0075\n",
    "layers_dims = [20, 7, 5, 1] # no. of hidden layer units in each hidden layer\n",
    "activation = ['relu', 'relu', 'relu', 'sigmoid'] #activation function (relu/sigmoid) corresponding to each hidden layer.\n",
    "#activation function for the output layer will be sigmoid function.\n",
    "\n",
    "#execution\n",
    "#import_libraries()\n",
    "x_train_orig, y_train, x_test_orig, y_test = load_data()\n",
    "x_train, x_test = transform_data(x_train_orig, x_test_orig)\n",
    "m = y_train.shape[1]\n",
    "layers_dims.insert(0,x_train.shape[0])\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "parameters, costs = train_model(x_train, y_train, parameters, activation, num_iterations, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training dataset: 99.04306220095694%\n",
      "Accuracy for test dataset: 82.0%\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(x_train, y_train, parameters, activation)\n",
    "print('Accuracy for training dataset: ' + str(predictions_train) + '%')\n",
    "predictions_test = predict(x_test, y_test, parameters, activation)\n",
    "print('Accuracy for test dataset: ' + str(predictions_test) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
